# Sistema de agentes para chatbot de mÃºltiples CVs



Este proyecto implementa un **asistente inteligente** que responde preguntas sobre diferentes CVs (Julio, Jose, Carlos), utilizando:

- **Streamlit** para la interfaz web interactiva.
- **LangChain** para orquestar prompts y agentes.
- **Pinecone** como vector store para recuperaciÃ³n de contexto (RAG).
- **OpenAI API** (vÃ­a GitHub Token) como motor de chat.
- **Embeddings de HuggingFace** para procesar los documentos PDF de los CVs.

---

## ðŸ›  Arquitectura General del Proyecto

A continuaciÃ³n se muestra un esquema general de la arquitectura de agentes utilizada:

![Arquitectura del proyecto](nlp2_tp2.png)

El flujo se organiza de la siguiente manera:

- **Decisor**: Analiza la pregunta del usuario y determina a quÃ© CV (o CVs) corresponde.
- **Agentes individuales**: Analizan preguntas especÃ­ficas para Julio, Jose o Carlos basÃ¡ndose en su propio CV.
- **Mixer**: Si la pregunta involucra mÃ¡s de un CV, este agente combina los contextos de todos los CVs relevantes.
- **Bases vectoriales en Pinecone**: Cada CV tiene su propio Ã­ndice de vectores, ademÃ¡s de un Ã­ndice combinado para el Mixer.

Todo el sistema funciona utilizando recuperaciÃ³n de informaciÃ³n (RAG) + razonamiento asistido, sobre una interfaz amigable desarrollada en **Streamlit**.

---

## ðŸ“‚ Estructura de Carpetas

```plaintext
nlp2_tp2/
â”‚
â”œâ”€â”€ main.py                  # CÃ³digo nuevo modularizado
â”œâ”€â”€ main_old.py              # CÃ³digo original (monolÃ­tico)
â”œâ”€â”€ requirements.txt         # Dependencias del proyecto
â”œâ”€â”€ API_KEYS.txt             # Claves GITHUB_TOKEN y PINECONE_API_KEY
â”‚
â”œâ”€â”€ cv/                      # Carpeta con los CVs
â”‚   â”œâ”€â”€ cv_julio_donadello.pdf
â”‚   â”œâ”€â”€ cv_jose_martinez.pdf
â”‚   â””â”€â”€ cv_carlos_garcia.pdf
â”‚
â”œâ”€â”€ agents/                  # LÃ³gica de construcciÃ³n de agentes
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent_factory.py
â”‚   â””â”€â”€ prompts.py
â”‚
â”œâ”€â”€ utils/                   # Utilidades generales
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ pinecone_utils.py
â”‚   â””â”€â”€ common.py
â”‚
â”œâ”€â”€ demo_videos/             # Carpeta con videos de demostraciÃ³n
â”‚   â”œâ”€â”€ demo_1.mp4
â”‚   â”œâ”€â”€ demo_2.mp4
â”‚   â””â”€â”€ ...

__init__.py vacÃ­os solo para que Python los reconozca como paquetes.
```
---

## ðŸš€ Â¿CÃ³mo correrlo?

Primero asegurate de tener el entorno preparado:

```bash
pip install -r requirements.txt
```

---

### ðŸ‘‰ Para correr el proyecto original (`main_old.py`)

```bash
streamlit run main_old.py
```

Este archivo contiene el flujo monolÃ­tico, donde todo el cÃ³digo estÃ¡ en un solo archivo.

---

### ðŸ‘‰ Para correr el proyecto nuevo (`main.py` modularizado)

```bash
streamlit run main.py
```

Este archivo organiza el proyecto de forma limpia en **agentes** y **utilidades** para un flujo mucho mÃ¡s escalable y profesional.

---

## ðŸ“¹ Videos de demostraciÃ³n

PodÃ©s encontrar videos grabados mostrando el funcionamiento en la carpeta:

[ðŸ“‚ Ir a demo_videos/](demo_videos/)

---

## ðŸ”¥ TecnologÃ­as utilizadas

- Python 3.10+
- Streamlit
- LangChain
- Pinecone
- HuggingFace Sentence Transformers
- OpenAI API vÃ­a Azure
- PyPDF2
- TheFuzz (para pequeÃ±as correcciones de texto)

---

## âœ¨ Notas importantes

- Si el Ã­ndice de Pinecone para un CV no existe o estÃ¡ vacÃ­o, se carga automÃ¡ticamente desde los PDFs en `cv/`.
- El agente **Mixer** combina los 3 CVs cuando una pregunta involucra mÃºltiples personas.
- Todo el proyecto estÃ¡ preparado para ser escalable, permitiendo agregar nuevos CVs, agentes y fuentes de datos fÃ¡cilmente.
- Para considerar un CV particular, se debe especificar el nombre del postulante. Si se especifican dos o mÃ¡s nombres, el sistema lee por defecto todos los CVs.

---
